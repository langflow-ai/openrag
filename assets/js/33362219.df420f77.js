"use strict";(self.webpackChunkopenrag_docs=self.webpackChunkopenrag_docs||[]).push([[532],{3782:(e,n,t)=>{t.d(n,{Ay:()=>c,RM:()=>a});var o=t(4848),s=t(8453),r=t(9179);const a=[];function i(e){const n={a:"a",p:"p",strong:"strong",...(0,s.R)(),...e.components};return(0,o.jsxs)(n.p,{children:["All flows included with OpenRAG are designed to be modular, performant, and provider-agnostic.\nTo modify a flow, click ",(0,o.jsx)(r.A,{name:"Settings2","aria-hidden":"true"})," ",(0,o.jsx)(n.strong,{children:"Settings"}),", and click ",(0,o.jsx)(n.strong,{children:"Edit in Langflow"}),".\nFlows are edited in the same way as in the ",(0,o.jsx)(n.a,{href:"https://docs.langflow.org/concepts-overview",children:"Langflow visual editor"}),"."]})}function c(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(i,{...e})}):i(e)}},8748:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>h,contentTitle:()=>l,default:()=>g,frontMatter:()=>c,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"core-components/agents","title":"Agents powered by Langflow","description":"OpenRAG leverages Langflow\'s Agent component to power the OpenRAG OpenSearch Agent flow.","source":"@site/docs/core-components/agents.mdx","sourceDirName":"core-components","slug":"/agents","permalink":"/agents","draft":false,"unlisted":false,"editUrl":"https://github.com/openrag/openrag/tree/main/docs/docs/core-components/agents.mdx","tags":[],"version":"current","frontMatter":{"title":"Agents powered by Langflow","slug":"/agents"},"sidebar":"tutorialSidebar","previous":{"title":"Terminal Interface (TUI)","permalink":"/get-started/tui"},"next":{"title":"OpenSearch Knowledge","permalink":"/knowledge"}}');var s=t(4848),r=t(8453),a=t(9179),i=(t(1470),t(9365),t(3782));const c={title:"Agents powered by Langflow",slug:"/agents"},l=void 0,h={},d=[{value:"Use the OpenRAG OpenSearch Agent flow",id:"use-the-openrag-opensearch-agent-flow",level:2},...i.RM];function p(e){const n={a:"a",code:"code",h2:"h2",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components},{Details:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"OpenRAG leverages Langflow's Agent component to power the OpenRAG OpenSearch Agent flow."}),"\n",(0,s.jsx)(n.p,{children:"This flow intelligently chats with your knowledge by embedding your query, comparing it the vector database embeddings, and generating a response with the LLM."}),"\n",(0,s.jsx)(n.p,{children:"The Agent component shines here in its ability to make decisions on not only what query should be sent, but when a query is necessary to solve the problem at hand."}),"\n",(0,s.jsxs)(t,{closed:!0,children:[(0,s.jsx)("summary",{children:"How do agents work?"}),(0,s.jsx)(n.p,{children:"Agents extend Large Language Models (LLMs) by integrating tools, which are functions that provide additional context and enable autonomous task execution. These integrations make agents more specialized and powerful than standalone LLMs."}),(0,s.jsx)(n.p,{children:"Whereas an LLM might generate acceptable, inert responses to general queries and tasks, an agent can leverage the integrated context and tools to provide more relevant responses and even take action. For example, you might create an agent that can access your company's documentation, repositories, and other resources to help your team with tasks that require knowledge of your specific products, customers, and code."}),(0,s.jsx)(n.p,{children:"Agents use LLMs as a reasoning engine to process input, determine which actions to take to address the query, and then generate a response. The response could be a typical text-based LLM response, or it could involve an action, like editing a file, running a script, or calling an external API."}),(0,s.jsx)(n.p,{children:"In an agentic context, tools are functions that the agent can run to perform tasks or access external resources. A function is wrapped as a Tool object with a common interface that the agent understands. Agents become aware of tools through tool registration, which is when the agent is provided a list of available tools typically at agent initialization. The Tool object's description tells the agent what the tool can do so that it can decide whether the tool is appropriate for a given request."})]}),"\n",(0,s.jsx)(n.h2,{id:"use-the-openrag-opensearch-agent-flow",children:"Use the OpenRAG OpenSearch Agent flow"}),"\n",(0,s.jsxs)(n.p,{children:["If you've chatted with your knowledge in OpenRAG, you've already experienced the OpenRAG OpenSearch Agent chat flow.\nTo view the flow, click ",(0,s.jsx)(a.A,{name:"Settings2","aria-hidden":"true"})," ",(0,s.jsx)(n.strong,{children:"Settings"}),", and then click ",(0,s.jsx)(n.strong,{children:"Edit in Langflow"}),".\nThis flow contains seven components:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["The Agent component orchestrates the entire flow by deciding when to search the knowledge base, how to formulate search queries, and how to combine retrieved information with the user's question to generate a comprehensive response.\nThe Agent behaves according to the prompt in the ",(0,s.jsx)(n.strong,{children:"Agent Instructions"})," field."]}),"\n",(0,s.jsx)(n.li,{children:"The Chat Input component is connected to the Agent component's Input port. This allows to flow to be triggered by an incoming prompt from a user or application."}),"\n",(0,s.jsx)(n.li,{children:"The OpenSearch component is connected to the Agent component's Tools port. The agent may not use this database for every request; the agent only uses this connection if it decides the knowledge can help respond to the prompt."}),"\n",(0,s.jsx)(n.li,{children:"The Language Model component is connected to the Agent component's Language Model port. The agent uses the connected LLM to reason through the request sent through Chat Input."}),"\n",(0,s.jsx)(n.li,{children:"The Embedding Model component is connected to the OpenSearch component's Embedding port. This component converts text queries into vector representations that are compared with document embeddings stored in OpenSearch for semantic similarity matching. This gives your Agent's queries context."}),"\n",(0,s.jsxs)(n.li,{children:["The Text Input component is populated with the global variable ",(0,s.jsx)(n.code,{children:"OPENRAG-QUERY-FILTER"}),".\nThis filter is the Knowledge filter, and filters which knowledge sources to search through."]}),"\n",(0,s.jsx)(n.li,{children:"The Agent component's Output port is connected to the Chat Output component, which returns the final response to the user or application."}),"\n"]}),"\n",(0,s.jsx)(i.Ay,{}),"\n",(0,s.jsxs)(n.p,{children:["For an example of changing out the agent's LLM in OpenRAG, see the ",(0,s.jsx)(n.a,{href:"/quickstart#change-components",children:"Quickstart"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["To restore the flow to its initial state, in OpenRAG, click ",(0,s.jsx)(a.A,{name:"Settings","aria-hidden":"true"})," ",(0,s.jsx)(n.strong,{children:"Settings"}),", and then click ",(0,s.jsx)(n.strong,{children:"Restore Flow"}),".\nOpenRAG warns you that this discards all custom settings. Click ",(0,s.jsx)(n.strong,{children:"Restore"})," to restore the flow."]})]})}function g(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(p,{...e})}):p(e)}},9179:(e,n,t)=>{t.d(n,{A:()=>r});t(6540);var o=t(4827),s=t(4848);function r({name:e,...n}){const t=o[e];return t?(0,s.jsx)(t,{...n}):null}}}]);